# Importa√ß√µes necess√°rias para o streamlit, api do google, leitura em json, lottie e etc.
import streamlit as st
import requests
from PIL import Image
import google.generativeai as genai
import PIL.Image
import pathlib
import tqdm
import os
import time
import json
import fitz
import tempfile
import PyPDF2
from io import BytesIO
from streamlit_lottie import st_lottie #Import de arquivos lottie animados
from dotenv import load_dotenv

# Padr√£o da p√°gina como centralizado
st.set_page_config(layout="centered")

# Carregando arquivo .env (vari√°veis de ambiente) e pegando nossa KEY da API
load_dotenv()

API_KEY = os.getenv("API_KEY");
genai.configure(api_key = API_KEY);
model = genai.GenerativeModel('gemini-1.5-flash')
chat = model.start_chat(history=[])

messages = []
image_messages = []
pdf_messages = []

### Vari√°veis Globais de state
if "selected_language" not in st.session_state:
    st.session_state["selected_language"] = "English"

if "selected_font_size" not in st.session_state:
    st.session_state["selected_font_size"] = "Medium"

if "selected_background" not in st.session_state:
    st.session_state["selected_background"] = "Padr√£o"

if "selected_background_messages" not in st.session_state:
    st.session_state["selected_background_messages"] = "Padr√£o"

# Importando pasta de CSS para estiliza√ß√µes globais
def local_css(file_name):
    with open(file_name) as f:
        
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

local_css("./styles.css");

############# FUN√á√ïES 
def set_language(language):
    st.session_state["selected_language"] = language
    #st.rerun() apenas para testes

# Fun√ß√£o para atualizar o container
def update_chat_container():
    chat_message_html = f"""<div id="chat-area">{''.join([f'<div class="message {message_class}"><b>{user}:</b> {message}</div>' for user, message in messages])}</div>"""
    # Exibe as mensagens no Streamlit
    st.markdown(chat_message_html, unsafe_allow_html=True)

        
# Fun√ß√£o para processar o envio de mensagem do chat
def process_chat_message(user_input):
    if user_input:
        response = chat.send_message(user_input)

        # Lingua selecionada
        selected_language = st.session_state["selected_language"]

        if selected_language == "Portugu√™s": 
            pronome = "Voc√™"
        else:
            pronome = "You"
        st.session_state.messages.append((pronome, user_input))
        st.session_state.messages.append(("Gemini", response.text))
        update_chat_container()
        st.rerun()
    else:
        st.markdown('<span id="erro">Por favor, digite alguma coisa.</span>', unsafe_allow_html=True)

# Fun√ß√£o para alterar tamanho da fonte do site, √∫til para acessibilidade
def set_font_size(font_size):
    if font_size == "Small":
        st.markdown('<style>body { font-size: small; } p { font-size: small; } h1,h3 {font-size: 22px;}</style>', unsafe_allow_html=True)
    elif font_size == "Medium":
        st.markdown('<style>body { font-size: medium; } p,li,h3,ul,h1 { font-size: medium; }</style>', unsafe_allow_html=True)
    elif font_size == "Large":
        st.markdown('<style>body { font-size: large; } h3,h1 { font-size: 45px; } p {font-size: 30px;} p.aviso {font-size: 27px}</style>', unsafe_allow_html=True)

# Fun√ß√£o para alterar a cor do background do site, √∫til para acessibilidade
def set_background(color):
    if color == "Branco":
        st.markdown('''<style> [data-testid="stSidebarContent"] { background-color: #D7D5CD; } [data-testid="stAppViewContainer"] { background-color: white;} 
                    [data-testid="stHeader"] { background-color: white;}  [data-testid="stSidebarCollapseButton"] { background-color: #D7D5CD;} [data-testid="stMainMenu"] { background-color: #D7D5CD;} 
                    [data-testid="main-menu-list"] { background-color: #D7D5CD;} [data-testid="stImageCaption"] {color: black} p,li,ul,h3,h1,h2,button { color: black; }</style>''', unsafe_allow_html=True)
        
    elif color == "Padr√£o": 
        st.markdown('<style></style>', unsafe_allow_html=True)

# Fun√ß√£o para alterar a cor do background das mensagens, √∫til para acessibilidade
def set_background_messages(color_message):
    if color_message == "Branco e Preto":
        st.markdown('<style> div.message.user { background-color: white; color: black} div.message.bot{ background-color: black;}</style>', unsafe_allow_html=True)
        
    elif color_message == "Padr√£o": 
        st.markdown('<style></style>', unsafe_allow_html=True)

    elif color_message == "Azul Claro e Roxo":
        st.markdown('<style> div.message.user { background-color: #85D4FD; color: black} div.message.bot{ background-color: purple;} </style>', unsafe_allow_html=True)
    
    elif color_message == "Azul Claro e Cinza":
        st.markdown('<style> div.message.user { background-color: #3797f0; color: white} div.message.bot{ background-color: gray;} </style>', unsafe_allow_html=True)
  
### Nessa pr√≥ximas duas fun√ß√µes foi referenciado de um projeto similiar que tamb√©m foi usado √°udios com 
#intelig√™ncia artificial, ent√£o bastou analisar e moldar conforme a necessidade
# Fun√ß√£o para processar o √°udio enviado
def process_audio(audio_file_path, user_prompt):
        model = genai.GenerativeModel("models/gemini-1.5-pro-latest")
        audio_file = genai.upload_file(path=audio_file_path)
        response = model.generate_content(
            [
                user_prompt,
                audio_file
            ]
        )
        return response.text

# Fun√ß√£o para salvar o arquivo de √°udio temporariamente
def save_uploaded_file(uploaded_file):
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix='.' + uploaded_file.name.split('.')[-1]) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                return tmp_file.name
        except Exception as e:
            st.error(f"Error: {e}")
            return None
######## Sidebars - Filtros

#Linguagem
with st.sidebar:
    language_options = ["English", "Portugu√™s"]
    st.markdown('''<style> [data-testid="stMarkdownContainer"] h1 { font-size: 45px; text-shadow: 2px -2px #466EFF; }</style>''', unsafe_allow_html=True)
    st.sidebar.title('SETTINGS ‚öôÔ∏è')

    with open('./img/Animation.json') as f:
        lottie_animation = json.load(f)
    
    st_lottie(lottie_animation)

    selected_language = st.selectbox("LINGUAGEM üåé", language_options)

    if selected_language != st.session_state["selected_language"]:
        set_language(selected_language)

#Fontes
with st.sidebar:
    font_size_options = ["Medium", "Small", "Large"]
    selected_font_size = st.selectbox("Font Size üîç", font_size_options)
    st.sidebar.markdown("---")
    
    if selected_font_size != st.session_state["selected_font_size"]:
        set_font_size(selected_font_size)

#Background Color
with st.sidebar:
    background_options = ["Padr√£o", "Branco"]
    selected_background = st.radio(" Background üé®", background_options)

    if selected_background != st.session_state["selected_background"]:
        set_background(selected_background)

#Message-Colors
with st.sidebar:
    background_options_messages = ["Padr√£o", "Branco e Preto", "Azul Claro e Roxo", "Azul Claro e Cinza"]
    selected_background_messages = st.radio(" Background Messages üé®", background_options_messages)
    st.sidebar.markdown("---")
    st.image('./img/gemini.png', caption='Powered by Gemini AI')

    if selected_background_messages != st.session_state["selected_background_messages"]:
        set_background_messages(selected_background_messages)





#### Come√ßo das p√°ginas e utiliza√ß√£o do Bot

# stSidebarContent
st.title("Chat Bot ü§ñüí≠ ")

#Mudando linguagem da aba conforme o filtro
if selected_language == "Portugu√™s":
        aba1, aba2, aba3, aba4, aba5 = st.tabs(['Chat Bot Geral','An√°lise de Imagens','An√°lise de PDFs', 'An√°lise de √Åudio', 'Sobre']);
elif selected_language == "English":
        aba1, aba2, aba3, aba4, aba5 = st.tabs(['Chat Bot Geral','Image Review','PDFs Review', 'Audio Review', 'About']);

with aba1:
    if selected_language == "Portugu√™s":
        st.write("### Chat Bot:")
        st.write(" üìç **Pergunte o que quiser!** Diga um oi, pergunte qual a origem da roupa branca no reveillon, por que o c√©u √© azul?, deixe a criatividade rolar solta (n√£o use o bot para consultas de pesquisas, v√° atr√°s para confiar as informa√ß√µes, sempre bom ter uma fonte confi√°vel);")
        st.markdown('<p class = aviso>Aviso: Dependendo da pergunta, o bot pode acrescentar muito texto e n√£o enviar a resposta. Seja pontual. Se o bot der algum erro, pe√ßa para ele resumir a resposta, deve funcionar.</p>', unsafe_allow_html=True);

        chat_container = st.container()

        if 'messages' not in st.session_state:
            st.session_state.messages = []

        with chat_container:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for user, message in st.session_state.messages:
                message_class = "user" if user == "Voc√™" else "bot"
                st.markdown(f'<div class="message {message_class}"><b>{user}:</b> {message}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("Diga alguma coisa... ", key = "user_input")
        if user_input:
            with st.spinner('Processando...'):
                process_chat_message(user_input);

        st.markdown("<div id='chat-area' style='overflow-y: auto; max-height: 500px;'></div>", unsafe_allow_html=True)
    elif selected_language == "English":
        st.write("### Chat Bot:")
        st.write(" üìç **Ask anything you want!** Say hello, ask where the white clothes come from on New Year's Eve, why the sky is blue, let your creativity run wild (don't use the bot for research queries, go back and trust the information, it's always good to have a reliable source).")
        st.markdown('<p class = aviso>Note: Depending on the question, the bot may add a lot of text and not send the answer. Be punctual. If the bot gives an error, ask it to summarise the answer, it should works.</p>', unsafe_allow_html=True);

        chat_container = st.container()

        if 'messages' not in st.session_state:
            st.session_state.messages = []

        with chat_container:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for user, message in st.session_state.messages:
                message_class = "user" if user == "You" else "bot"
                st.markdown(f'<div class="message {message_class}"><b>{user}:</b> {message}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("Write something... ", key = "user_input")

        if user_input:
            with st.spinner('Processing...'):
                process_chat_message(user_input);
        
        st.markdown("<div id='chat-area' style='overflow-y: auto; max-height: 500px;'></div>", unsafe_allow_html=True)


#Agora para a aba2, foi fundamental acessar a documenta√ß√£o do gemini, aqui precisamos alterar o modelo da IA, 
#para que possamos conversar enviando imagens. De resto, repitimos o processo da aba1
with aba2:  
 if selected_language == "Portugu√™s":
    st.write("### An√°lise de Imagens com IA")
    st.write("üìç **Envie uma imagem!**: Envie uma imagem e pergunte o que quiser sobre ela para a IA!")
    st.markdown("<p class = aviso >Aviso: A IA l√™ imagens de at√© 20MB.</p>", unsafe_allow_html=True);

    model = genai.GenerativeModel('gemini-1.5-flash') ## para analisar as imagens, precisamos de outra vers√£o do gemini
    uploaded_file = st.file_uploader("Escolha uma imagem...", type=["jpg", "jpeg", "png"])
    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption='Imagem Enviada', use_column_width=True)
        st.write("Analisando a imagem...")

        if 'image_messages' not in st.session_state:
            st.session_state.image_messages = []

        if len(st.session_state.image_messages) == 0:
            st.session_state.image_messages.append(("Voc√™", f"Analise esta imagem: {uploaded_file.name}"))
            response = model.generate_content(["Analize esta imagem", image]) #Primeira pergunta padr√£o que ser√° enviada, mas depois podemos fazer mais
            response.resolve()
            st.session_state.image_messages.append(("Gemini", response.text))

        chat_container = st.container()
        with chat_container:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for user, message in st.session_state.image_messages:
                message_class = "user" if user == "Voc√™" else "bot"
                st.markdown(f'<div class="message {message_class}"><b>{user}:</b> {message}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("Pergunte algo sobre a imagem...", key="image_user_input")
        if user_input:
            st.session_state.image_messages.append(("Voc√™", user_input))
            response = model.generate_content([user_input, image])
            response.resolve()
            st.session_state.image_messages.append(("Gemini", response.text))
            st.rerun()

 elif selected_language == "English":
    st.write("### Image Review with AI")
    st.write("üìç **Upload an image!**: Upload an image and ask the AI anything about it!")
    st.markdown("<p class = aviso>Note: IA supports up to 20MB upload</p>", unsafe_allow_html=True)

    model = genai.GenerativeModel('gemini-1.5-flash') ## para analisar as imagens, precisamos de outra vers√£o do gemini
    uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"], key = "image")
    if uploaded_file is not None:
        image = PIL.Image.open(uploaded_file)
        st.image(image, caption='Uploaded Image', use_column_width=True)
        st.write("Analyzing the image...")

        if 'image_messages' not in st.session_state:
            st.session_state.image_messages = []

        if len(st.session_state.image_messages) == 0:
            st.session_state.image_messages.append(("You", f"Analyze this image: {uploaded_file.name}"))
            response = model.generate_content(["Analyze this image", image])
            response.resolve()
            st.session_state.image_messages.append(("Gemini", response.text))

        chat_container = st.container()
        with chat_container:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for user, message in st.session_state.image_messages:
                message_class = "user" if user == "You" else "bot"
                st.markdown(f'<div class="message {message_class}"><b>{user}:</b> {message}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("Ask something about the image...", key="image_user_input")

        if user_input:
            st.session_state.image_messages.append(("You", user_input))
            response = model.generate_content([user_input, image])
            response.resolve()
            #response = chat.send_message(response1)
            st.session_state.image_messages.append(("Gemini", response.text))
            st.rerun()



#Agora na aba3, teremos alguns pontos similares ao da aba2, por√©m agora iremos analisar os textos contidos em um PDF,
#n√£o trabalharemos com imagens. Al√©m disso, precisamos converter o pdf para bytes.
with aba3:
  if selected_language == "Portugu√™s":
    st.write("### An√°lise de PDFs com IA");
    st.write("üìç **Envie um arquivo PDF!**: Envie seu curr√≠culo, um livro, revista, e pergunte sobre ele para a IA, quer um resumo? um conselho? Teste agora!")
    st.markdown("<p class = aviso> Caso d√™ algum erro na leitura, tenha certeza que seu arquivo PDF esteja corretamente formatado. A IA ir√° ler o conte√∫do do seu PDF, ignorando imagens.</p>", unsafe_allow_html=True);
    uploaded_file_pdf = st.file_uploader("Escolha um PDF...", type=["pdf"])
    
    if uploaded_file_pdf is not None:
        # O gmeini precisa fazer leitura em bytes, segundo a pr√≥pria documenta√ß√£o, ent√£o vamos transformar o arquivo PDF em bytes
        pdf_bytes = BytesIO(uploaded_file_pdf.read())
        
        leitor_pdf = PyPDF2.PdfReader(pdf_bytes)

        num_paginas = len(leitor_pdf.pages)
        texto_completo = ""

        # Aqui vamos extrair o texto de cada p√°gina, ja que √© assim que o gemini ir√° ler. Vamos s√≥ analisar texto, nada de imagens
        for num_pagina in range(num_paginas):
            pagina = leitor_pdf.pages[num_pagina]

            texto_pagina = pagina.extract_text()
            texto_completo += texto_pagina + "\n"

        # O melhor modelo do gemini para a leitura de textos em pdf
        model = genai.GenerativeModel('gemini-1.5-pro-latest')

        if 'pdf_messages' not in st.session_state:
            st.session_state.pdf_messages = []

        if len(st.session_state.pdf_messages) == 0:
            st.session_state.pdf_messages.append(("Voc√™", f"Analise este PDF: {uploaded_file_pdf.name}"))
            response = model.generate_content([f"Analise este PDF", texto_completo])
            response.resolve()
            st.session_state.pdf_messages.append(("Gemini", response.text))

        chat_container = st.container()
        with chat_container:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for user, message in st.session_state.pdf_messages:
                message_class = "user" if user == "Voc√™" else "bot"
                st.markdown(f'<div class="message {message_class}"><b>{user}:</b> {message}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("Pergunte algo sobre o PDF...", key="pdf_user_input")
        if user_input:
            st.session_state.pdf_messages.append(("Voc√™", user_input))
            response = model.generate_content([user_input, texto_completo])
            response.resolve()
            st.session_state.pdf_messages.append(("Gemini", response.text))
            st.rerun()

    #Agora replicamos, mas trocando o idioma
  elif selected_language == "English":
    st.write("### PDF's Review with an IA");
    st.write("üìç **Send a PDF file!**: Send your resume/curriculum, a magazine, a book, ask about it to the IA, wants a summary? an advice? Try it now!")
    st.markdown("<p class = aviso> If there is an error when reading PDF file, make sure your file is correctly formatted. The AI will read the content of your PDF, ignoring images. </p>", unsafe_allow_html=True);
    uploaded_file_pdf = st.file_uploader("Choose a PDF File...", type=["pdf"])
    
    if uploaded_file_pdf is not None:
        pdf_bytes = BytesIO(uploaded_file_pdf.read())
        
        leitor_pdf = PyPDF2.PdfReader(pdf_bytes)

        num_paginas = len(leitor_pdf.pages)
        texto_completo = ""

        for num_pagina in range(num_paginas):
            pagina = leitor_pdf.pages[num_pagina]

            texto_pagina = pagina.extract_text()
            texto_completo += texto_pagina + "\n"

        model = genai.GenerativeModel('gemini-1.5-pro-latest')

        if 'pdf_messages' not in st.session_state:
            st.session_state.pdf_messages = []

        if len(st.session_state.pdf_messages) == 0:
            st.session_state.pdf_messages.append(("Voc√™", f"Analise este PDF: {uploaded_file_pdf.name}"))
            response = model.generate_content([f"Analise este PDF", texto_completo])
            response.resolve()
            st.session_state.pdf_messages.append(("Gemini", response.text))

        chat_container = st.container()
        with chat_container:
            st.markdown('<div class="chat-container">', unsafe_allow_html=True)
            for user, message in st.session_state.pdf_messages:
                message_class = "user" if user == "Voc√™" else "bot"
                st.markdown(f'<div class="message {message_class}"><b>{user}:</b> {message}</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)

        user_input = st.chat_input("Pergunte algo sobre o PDF...", key="pdf_user_input")
        if user_input:
            st.session_state.pdf_messages.append(("Voc√™", user_input))
            response = model.generate_content([user_input, texto_completo])
            response.resolve()
            st.session_state.pdf_messages.append(("Gemini", response.text))
            st.rerun()


# Nessa etapa de an√°lise de √°udios, foi necess√°rio al√©m de checar a documenta√ß√£o, consultar alguns projetos similares no github,
#pois estava ocasionando alguns problemas. Por fim deu tudo certo. Algumas partes parecidas com as abas anteriores.
with aba4:
  if selected_language == "Portugu√™s":
    st.write("### An√°lise de √Åudio");
    st.write("üìç **Envie um √°udio!**:  Envie um √°udio e fa√ßa alguma pergunte sobre ele, quer um resumo de um a√∫dio de 10 minutos? Teste !")
    st.markdown("<p class = aviso> O √°udio deve conter falas, o bot ir√° principalmente analisar falas (que n√£o contenham linguajar expl√≠cito/obscenidades!). √Åudios que contenham barulhos/m√∫sica, s√£o prov√°veis a dar erro. </p>", unsafe_allow_html=True);

    user_prompt = st.text_input("Digite sua quest√£o sobre o √°udio:", placeholder="Que tal... 'Me resuma esse √°udio'")

    audio_file = st.file_uploader("Envie seu arquivo", type=['wav', 'mp3'])
    if audio_file is not None:
        audio_path = save_uploaded_file(audio_file)
        st.audio(audio_path)

        if st.button('Processar!'):
            with st.spinner('Processando...'):
                processed_text = process_audio(audio_path, user_prompt)
                st.text_area("Resposta: ", processed_text, height=300)

  elif selected_language == "English":
    st.write("### Audio Review")
    st.write("üìç **Send an audio!**: Send an audio and ask a question about it, want a summary of a 10-minute audio? Try it out!")
    st.markdown("<p class = aviso> The audio must contain speech, the bot will mainly analyse speech (that doesn't contain explicit language/obscenities!). Audio that contains noise/music is likely to give an error. </p>", unsafe_allow_html=True);

    user_prompt = st.text_input("Enter your custom AI prompt:", placeholder="E.g., 'Please summarize the audio:'")

    audio_file = st.file_uploader("Upload Audio File", type=['wav', 'mp3'])
    if audio_file is not None:
        audio_path = save_uploaded_file(audio_file)
        st.audio(audio_path)

        if st.button('Process Audio'):
            with st.spinner('Processing...'):
                processed_text = process_audio(audio_path, user_prompt)
                st.text_area("Processed Output", processed_text, height=300)


with aba5:
  # Conte√∫do Din√¢mico com Base no Idioma
  if selected_language == "Portugu√™s":
    st.write("### Sobre");
    st.write("Este site foi contruido usando a biblioteca Streamlit do python atrav√©s da API do Google Gemini, a inteligencia artificial do Google.")

    # Gemini
    st.image('./img/gemini.png', caption='Gemini AI')
    #Streamlit
    st.image('./img/Streamlit.png', caption='Streamlit Logo')

  elif selected_language == "English":
    st.write("### About");
    st.write("This site was built using the Streamlit python library via the Google Gemini API, Google's artificial intelligence.")
    
    #Gemini
    st.image('./img/gemini.png', caption='Gemini AI')

    #Streamlit
    st.image('./img/Streamlit.png', caption='Streamlit Logo')
